{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4EkRfuDWKBWN3gAG7hbxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akanksha0911/Multi-Task-Learning-and-Transfer-Learning-/blob/main/head2toe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer-learning methods aim to improve performance in a data-scarce target domain using a model pretrained on a data-rich source domain. A cost-efficient strategy, linear probing, involves freezing the source model and training a new classification head for the target domain."
      ],
      "metadata": {
        "id": "IUwjI1DFZ63-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Head-to-Toe probing (Head2Toe), that selects features from all layers of the source model to train a classification head for the target-domain. In evaluations on the VTAB-1k, Head2Toe matches performance obtained with fine-tuning on average while reducing training and storage cost hundred folds or more, but critically, for out-of-distribution transfer, Head2Toe outperforms fine-tuning."
      ],
      "metadata": {
        "id": "JNUg-e-QZ0tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/google-research/task_adaptation.git#egg=task_adaptation"
      ],
      "metadata": {
        "id": "tjNmJqGdr50I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import functools\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "from task_adaptation import data_loader\n",
        "import tensorflow.compat.v2 as tf"
      ],
      "metadata": {
        "id": "yEnlqrElZ1L8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _filter_to_k_shot(dataset, num_classes, k):\n",
        "  \"\"\"Filters k-shot subset from a dataset.\"\"\"\n",
        "  # !!! IMPORTANT: the dataset should *not* be shuffled. !!!\n",
        "  # Make sure that `shuffle_buffer_size=1` in the call to\n",
        "  # `dloader.get_tf_data`.\n",
        "\n",
        "  # Indices of included examples in the k-shot balanced dataset.\n",
        "  keep_example = []\n",
        "  # Keep track of the number of examples per class included in\n",
        "  # `keep_example`.\n",
        "  class_counts = np.zeros([num_classes], dtype=np.int32)\n",
        "  for _, label in dataset.as_numpy_iterator():\n",
        "    # If there are less than `k` examples of class `label` in `example_indices`,\n",
        "    # keep this example and update the class counts.\n",
        "    keep = class_counts[label] < k\n",
        "    keep_example.append(keep)\n",
        "    if keep:\n",
        "      class_counts[label] += 1\n",
        "    # When there are `k` examples for each class included in `keep_example`,\n",
        "    # stop searching.\n",
        "    if (class_counts == k).all():\n",
        "      break\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((\n",
        "      tf.data.Dataset.from_tensor_slices(keep_example),\n",
        "      dataset\n",
        "  )).filter(lambda keep, _: keep).map(lambda _, example: example).cache()\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "ljBaGRIyZ1Ip"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bxkmLKHJZqFe"
      },
      "outputs": [],
      "source": [
        "def create_vtab_dataset_balanced(dataset, image_size, batch_size,\n",
        "                                 data_fraction):\n",
        "  \"\"\"Creates a VTAB input_fn to be used by `tf.Estimator`.\n",
        "  Deterministic balanced sampling from vtab datasets.\n",
        "  Args:\n",
        "    dataset: str, VTAB task to evaluate on.\n",
        "    image_size: int\n",
        "    batch_size: int\n",
        "    data_fraction: float, used to calculate n_shots\n",
        "  Returns:\n",
        "    input_fn, input function to be passed to `tf.Estimator`.\n",
        "  \"\"\"\n",
        "  dloader = data_loader.get_dataset_instance(\n",
        "      {'dataset': dataset, 'data_dir': None})\n",
        "  num_classes = dloader.get_num_classes()\n",
        "  n_shots = max(int(1000 * data_fraction / num_classes), 1)\n",
        "  logging.info('n_shots: %d', n_shots)\n",
        "  def _dict_to_tuple(batch):\n",
        "    return batch['image'], batch['label']\n",
        "  dataset = dloader.get_tf_data(\n",
        "      split_name='trainval',\n",
        "      batch_size=batch_size,\n",
        "      preprocess_fn=functools.partial(\n",
        "          data_loader.preprocess_fn,\n",
        "          input_range=(-1.0, 1.0),\n",
        "          size=image_size),\n",
        "      epochs=0,\n",
        "      drop_remainder=False,\n",
        "      for_eval=False,\n",
        "      shuffle_buffer_size=1,\n",
        "      prefetch=1,\n",
        "      train_examples=None,\n",
        "  ).unbatch().map(_dict_to_tuple)\n",
        "  filtered_dataset = _filter_to_k_shot(dataset, num_classes, n_shots)\n",
        "  return filtered_dataset.shuffle(1000).batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vtab_dataset(dataset, image_size, batch_size, mode,\n",
        "                        eval_mode='test', valid_fold_id=4):\n",
        "  \"\"\"Creates a VTAB input_fn to be used by `tf.Estimator`.\n",
        "  Note: There is one episode/VTAB dataset.\n",
        "  Args:\n",
        "    dataset: str, VTAB task to evaluate on.\n",
        "    image_size: int\n",
        "    batch_size: int\n",
        "    mode: str in {'train', 'eval'}, whether to build the input function for\n",
        "      training or evaluation.\n",
        "    eval_mode: str in {'valid', 'test'}, whether to build the input functions\n",
        "      for validation or test runs.\n",
        "    valid_fold_id: int, 0 <= valid_fold_id < 5, valid_fold_id=4 corresponds to\n",
        "      the default value in VTAB.\n",
        "  Returns:\n",
        "    input_fn, input function to be passed to `tf.Estimator`.\n",
        "  \"\"\"\n",
        "  assert 0 <= valid_fold_id < 5\n",
        "  dloader = data_loader.get_dataset_instance(\n",
        "      {'dataset': dataset, 'data_dir': None})\n",
        "  if mode not in ('train', 'eval'):\n",
        "    raise ValueError(\"mode should be 'train' or 'eval'\")\n",
        "  is_training = mode == 'train'\n",
        "\n",
        "  def _dict_to_tuple(batch):\n",
        "    return batch['image'], batch['label']\n",
        "  if eval_mode == 'test':\n",
        "    split_name = 'train800val200' if is_training else 'test'\n",
        "  elif eval_mode == 'valid':\n",
        "    val_start, val_end = valid_fold_id * 200, (valid_fold_id + 1) * 200\n",
        "    if is_training:\n",
        "      split_name = f'train[:{val_start}]+train[{val_end}:1000]'\n",
        "    else:\n",
        "      split_name = f'train[{val_start}:{val_end}]'\n",
        "    logging.info('Using split_name: %s', split_name)\n",
        "\n",
        "    if split_name not in dloader._tfds_splits:\n",
        "      dloader._tfds_splits[split_name] = split_name\n",
        "      dloader._num_samples_splits[split_name] = 800 if is_training else 200\n",
        "  else:\n",
        "    raise ValueError(f'eval_mode: {eval_mode} invalid')\n",
        "\n",
        "  return dloader.get_tf_data(\n",
        "      split_name=split_name,\n",
        "      batch_size=batch_size,\n",
        "      preprocess_fn=functools.partial(\n",
        "          data_loader.preprocess_fn,\n",
        "          input_range=(-1.0, 1.0),\n",
        "          size=image_size),\n",
        "      epochs=0,\n",
        "      drop_remainder=False,\n",
        "      for_eval=not is_training,\n",
        "      # Our training data has at most 1000 samples, therefore a shuffle buffer\n",
        "      # size of 1000 is sufficient.\n",
        "      shuffle_buffer_size=1000,\n",
        "      prefetch=1,\n",
        "      train_examples=None,\n",
        "  ).map(_dict_to_tuple)"
      ],
      "metadata": {
        "id": "2c36OVAxsbaN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import copy\n",
        "import math\n",
        "from absl import logging\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "TeMc-te6sulV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_HEAD_TYPES = ['nohidden', 'random', 'trainable']"
      ],
      "metadata": {
        "id": "-Il4TC2qs004"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_aware_normalize(embedding, axis):\n",
        "  \"\"\"If the norm is zero leaves the row unnormalized.\"\"\"\n",
        "  # Following will have nans when the norm of vector(the divider) is zero.\n",
        "  normalized, norms = tf.linalg.normalize(embedding, axis=axis)\n",
        "  is_zero_norm = tf.broadcast_to(tf.equal(norms, 0), normalized.shape)\n",
        "  return tf.where(is_zero_norm, tf.zeros_like(embedding), normalized)"
      ],
      "metadata": {
        "id": "CtDVBFv2s3yN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _check_and_convert(norm_ord):\n",
        "  \"\"\"Validates the order is positive or 'inf'.\"\"\"\n",
        "  if isinstance(norm_ord, (float, int)) and norm_ord > 0:\n",
        "    return norm_ord\n",
        "  elif isinstance(norm_ord, str) and norm_ord == 'inf':\n",
        "    return np.inf\n",
        "  else:\n",
        "    raise ValueError(f'norm_order:{norm_ord} is not valid')\n"
      ],
      "metadata": {
        "id": "ayMAKF_Ms7YJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GroupLRP(tf.keras.regularizers.Regularizer):\n",
        "  \"\"\"A regularizer that applies Group L-r/p penalty to the weights.\n",
        "  The L-r/p regularization penalty is computed as:\n",
        "  `loss = coef * norm(norm(x, ord=r, axis=1), ord=p)`\n",
        "  Attributes:\n",
        "      coef: Float; regularization factor.\n",
        "      r: int, Must be >0. or 'inf'\n",
        "      p: int, Must be >0. or 'inf'\n",
        "      group_sizes: iterable or None; used to split feature vector into tensors.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, coef=0., r=2, p=1, group_sizes=None):\n",
        "    self.coef = tf.keras.backend.cast_to_floatx(coef)\n",
        "    self.r = _check_and_convert(r)\n",
        "    self.p = _check_and_convert(p)\n",
        "    self.group_sizes = group_sizes\n",
        "\n",
        "  def __call__(self, x):\n",
        "    regularization = tf.keras.backend.constant(0., dtype=x.dtype)\n",
        "    if self.coef:\n",
        "      if self.group_sizes:\n",
        "        group_norms = []\n",
        "        for group in tf.split(x, self.group_sizes, axis=0):\n",
        "          group_norms.append(tf.norm(tf.reshape(group, [-1]), ord=self.r))\n",
        "        regularization += tf.norm(tf.stack(group_norms), ord=self.p)\n",
        "      else:\n",
        "        regularization += self.coef * tf.norm(\n",
        "            tf.norm(x, axis=1, ord=self.r), ord=self.p)\n",
        "    return regularization\n",
        "\n",
        "  def get_config(self):\n",
        "    return {'coef': float(self.coef), 'r': self.r, 'p': self.p,\n",
        "            'group_sizes': tuple(self.group_sizes)}\n",
        "\n",
        "\n",
        "class Finetune(tf.keras.Model):\n",
        "  \"\"\"A `tf.keras.Model` implementation of Finetune.\n",
        "  This learner trains a linear classifier on top of the features given.\n",
        "  TODO Split finetune_backbone implementation from linear probe.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "    \"\"\"Initializes a `Finetune` instance.\n",
        "    Args:\n",
        "      config: a `ConfigDict` specifying the backbones configuration.\n",
        "    \"\"\"\n",
        "    super(Finetune, self).__init__()\n",
        "    self._backbone_config = config.backbone\n",
        "    self._learning_config = config.learning\n",
        "    available_gpus = tf.config.list_physical_devices(device_type='GPU')\n",
        "    if config.max_num_gpus > len(available_gpus):\n",
        "      logging.warning('config.max_num_gpus: %s > n_gpus', config.max_num_gpus)\n",
        "    else:\n",
        "      available_gpus = available_gpus[:config.max_num_gpus]\n",
        "    logging.info('N_GPUS: %d in use', len(available_gpus))\n",
        "    # To get /physical_device:GPU:0\n",
        "    available_gpus = [':'.join(g.name.split(':')[1:]) for g in available_gpus]\n",
        "    self.strategy = tf.distribute.MirroredStrategy(devices=available_gpus)\n",
        "    with self.strategy.scope():\n",
        "      res = self.load_backbones()\n",
        "      self.backbones, self.backbone_names, self.embedding_sizes = res\n",
        "\n",
        "  def load_backbones(self):\n",
        "    backbone_config = self._backbone_config\n",
        "    # Load pre-trained backbones.\n",
        "    backbones = []\n",
        "    backbone_names = []\n",
        "    embedding_sizes = []\n",
        "    for name, handle, signature, output_key, size in zip(\n",
        "        backbone_config.names,\n",
        "        backbone_config.handles,\n",
        "        backbone_config.signatures,\n",
        "        backbone_config.output_keys,\n",
        "        backbone_config.input_sizes):\n",
        "\n",
        "      if self._learning_config.finetune_backbones:\n",
        "        backbone = hub.KerasLayer(handle, trainable=True)\n",
        "      elif signature is None:\n",
        "        backbone = hub.KerasLayer(handle, trainable=False)\n",
        "      else:\n",
        "        backbone = hub.KerasLayer(\n",
        "            handle, signature=signature, output_key=None,\n",
        "            trainable=False, signature_outputs_as_dict=True)\n",
        "      inputs = tf.keras.Input(shape=(None, None, 3))\n",
        "      resized_inputs = inputs\n",
        "      if size is not None:\n",
        "        inputs = tf.keras.Input(shape=(size, size, 3))\n",
        "        resized_inputs = tf.image.resize(inputs, size=[size, size])\n",
        "      outputs = backbone(resized_inputs)\n",
        "      if backbone_config.additional_features:\n",
        "        updated_outputs = []\n",
        "        all_output_keys = [output_key]\n",
        "        if backbone_config.include_input:\n",
        "          outputs['input'] = resized_inputs\n",
        "          all_output_keys.append('input')\n",
        "        all_output_keys.extend(\n",
        "            backbone_config.additional_features.strip().split(','))\n",
        "        if backbone_config.additional_features_multi_target_sizes:\n",
        "          t_sizes = backbone_config.additional_features_multi_target_sizes\n",
        "          target_embedding_sizes = t_sizes.strip().split(',')\n",
        "        else:\n",
        "          target_embedding_sizes = [\n",
        "              backbone_config.additional_features_target_size]\n",
        "        # TODO Probably use the function to get multiple pooled features.\n",
        "        # It should also return the names maybe.\n",
        "        # Also it might be more straight forward to use pool_sizes.\n",
        "        for target_embedding_size in target_embedding_sizes:\n",
        "          new_outputs = flatten_and_concat(\n",
        "              outputs, output_keys=all_output_keys,\n",
        "              pool_size=backbone_config.additional_features_pool_size,\n",
        "              target_size=int(target_embedding_size),\n",
        "              cls_token_pool=backbone_config.cls_token_pool)\n",
        "          new_names = [f'{name}_{n}_{target_embedding_size}' for n\n",
        "                       in all_output_keys]\n",
        "          for newname, out in zip(new_names, new_outputs):\n",
        "            logging.info('Backbone name: %s, shape: %s', newname, out.shape)\n",
        "            backbone_names.append(newname)\n",
        "            embedding_sizes.append(out.shape[-1])\n",
        "          updated_outputs += new_outputs\n",
        "        outputs = updated_outputs\n",
        "      else:\n",
        "        outputs = outputs[output_key]\n",
        "        logging.info('Backbone name: %s, shape: %s', name, outputs.shape)\n",
        "        backbone_names.append(name)\n",
        "        embedding_sizes.append(outputs.shape[-1])\n",
        "      backbone = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "      backbones.append(backbone)\n",
        "    return backbones, backbone_names, embedding_sizes\n",
        "\n",
        "  def _get_optimizer(self, learning_config, n_classes):\n",
        "    learning_rate = learning_config.learning_rate\n",
        "    clipvalue = (learning_config.grad_clip_value\n",
        "                 if learning_config.grad_clip_value > 0 else None)\n",
        "    if learning_config.use_cosine_decay:\n",
        "      learning_rate = tf.keras.experimental.CosineDecay(\n",
        "          learning_rate, learning_config.training_steps)\n",
        "    optimizer = learning_config.optimizer\n",
        "    if optimizer == 'adam':\n",
        "      optimizer = tf.optimizers.Adam(learning_rate, clipvalue=clipvalue)\n",
        "    elif optimizer == 'sgd':\n",
        "      optimizer = tf.optimizers.SGD(learning_rate, momentum=0.9,\n",
        "                                    clipvalue=clipvalue)\n",
        "    else:\n",
        "      raise ValueError('Unknown optimizer')\n",
        "    return optimizer\n",
        "\n",
        "  def _embed_batch(self, x, is_training=False):\n",
        "    \"\"\"Compute the feature representation of a batch.\n",
        "    Args:\n",
        "      x: input tensor.\n",
        "      is_training: bool, passed to the backbone.\n",
        "    Returns:\n",
        "      embedding_list: A list of tf.Tensors.\n",
        "    \"\"\"\n",
        "    embedding_list = []\n",
        "    for backbone in self.backbones:\n",
        "      output_backbone = backbone(x, training=is_training)\n",
        "      # Note that the output of the backbone can be a list.\n",
        "      if isinstance(output_backbone, list):\n",
        "        for out in output_backbone:\n",
        "          embedding_list.append(out)\n",
        "      else:\n",
        "        embedding_list.append(output_backbone)\n",
        "    return embedding_list\n",
        "\n",
        "  def _embed_dataset(self, dataset):\n",
        "    \"\"\"Compute the feature representation of a batch.\n",
        "    Args:\n",
        "      dataset: a `tf.data.Dataset` corresponding to the support or query set.\n",
        "    Returns:\n",
        "      embeddings: A list of tf.Tensors.\n",
        "      labels: A tf.Tensor.\n",
        "    \"\"\"\n",
        "    batch_embedding_lists = []\n",
        "    labels = []\n",
        "    for x, y in dataset:\n",
        "      labels.append(y)\n",
        "      batch_embedding_lists.append(self._embed_batch(x))\n",
        "\n",
        "    labels = tf.concat(labels, axis=0)\n",
        "    output_embeddings = []\n",
        "    for i in range(len(batch_embedding_lists[0])):\n",
        "      embedding_i = [batch[i] for batch in batch_embedding_lists]\n",
        "      output_embeddings.append(tf.concat(embedding_i, axis=0))\n",
        "    return output_embeddings, labels\n",
        "\n",
        "  def _process_metrics(self, metrics):\n",
        "    (support_loss_iter, support_accuracy_iter, query_loss_iter,\n",
        "     query_accuracy_iter) = metrics\n",
        "\n",
        "    ret_dict = {\n",
        "        'support_loss': support_loss_iter[-1],\n",
        "        'support_accuracy': support_accuracy_iter[-1],\n",
        "        'query_loss': query_loss_iter[-1],\n",
        "        'query_accuracy': query_accuracy_iter[-1]\n",
        "                }\n",
        "\n",
        "    return ret_dict\n",
        "\n",
        "  def _process_embeddings(self, embeddings, selected_features,\n",
        "                          normalization='unit_vector'):\n",
        "    \"\"\"Processes embeddings by normalizing an concatenating.\n",
        "    Args:\n",
        "      embeddings: list of Tensors, where each Tensor is the embeddings\n",
        "        of a particular backbone.\n",
        "      selected_features: list of Tensors, where each Tensor indicates the\n",
        "        indices to be selected.\n",
        "      normalization: str, 'unit_vector', 'per_feature_std'.\n",
        "        'unit_vector' SUR style normalization\n",
        "        'per_feature' similar to Batch-Normalization\n",
        "    Returns:\n",
        "      flattened and possibly scaled embeddings.\n",
        "    \"\"\"\n",
        "    # shape= (n_image, n_features)\n",
        "    assert normalization in ('unit_vector', 'per_feature', '')\n",
        "    if selected_features:\n",
        "      # Following removes the backbones altogether if no feature is selected.\n",
        "      embeddings = [\n",
        "          tf.gather(embedding, indices, axis=1) for embedding, indices\n",
        "          in zip(embeddings, selected_features)\n",
        "          if np.prod(indices.shape) > 0\n",
        "      ]\n",
        "    if normalization == 'unit_vector':\n",
        "      embeddings = [zero_aware_normalize(e, axis=1) for e in embeddings]\n",
        "    embeddings = tf.concat(embeddings, -1)\n",
        "    if normalization == 'per_feature':\n",
        "      # Normalize each feature to have unit variance and zero mean.\n",
        "      mean, var = tf.nn.moments(embeddings, axes=0)\n",
        "      bn_args = {'offset': None,\n",
        "                 'scale': None,\n",
        "                 'variance_epsilon': 1e-5}\n",
        "      embeddings = tf.nn.batch_normalization(\n",
        "          embeddings, mean, var, **bn_args)\n",
        "    return embeddings\n",
        "\n",
        "  @tf.function(reduce_retracing=True)\n",
        "  def _compute_loss_and_accuracy(self, output_head, logits, labels,\n",
        "                                 global_batch_size=None):\n",
        "    \"\"\"Computes the loss and accuracy on an episode.\"\"\"\n",
        "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=labels, logits=logits)\n",
        "    if output_head.losses:\n",
        "      loss += tf.add_n(output_head.losses)\n",
        "    accuracy = tf.cast(tf.equal(\n",
        "        tf.math.argmax(logits, axis=1, output_type=labels.dtype),\n",
        "        labels), tf.float32)\n",
        "    loss = tf.nn.compute_average_loss(loss, global_batch_size=global_batch_size)\n",
        "    accuracy = tf.nn.compute_average_loss(accuracy,\n",
        "                                          global_batch_size=global_batch_size)\n",
        "    return loss, accuracy\n",
        "\n",
        "  def _init_training_vars(self, num_ways, learning_config):\n",
        "    if learning_config.l1_regularizer or learning_config.l2_regularizer:\n",
        "      regularizer = tf.keras.regularizers.L1L2(\n",
        "          l1=learning_config.l1_regularizer, l2=learning_config.l2_regularizer)\n",
        "    elif learning_config.group_lrp_regularizer_coef:\n",
        "      group_sizes = (self.embedding_sizes\n",
        "                     if learning_config.group_lrp_is_embedding else None)\n",
        "      regularizer = GroupLRP(\n",
        "          coef=learning_config.group_lrp_regularizer_coef,\n",
        "          group_sizes=group_sizes,\n",
        "          r=learning_config.group_lrp_regularizer_r,\n",
        "          p=learning_config.group_lrp_regularizer_p)\n",
        "    else:\n",
        "      regularizer = None\n",
        "    output_layers = []\n",
        "    assert any(learning_config.output_head_type.startswith(t)\n",
        "               for t in OUTPUT_HEAD_TYPES)\n",
        "    if learning_config.output_head_type.startswith('random'):\n",
        "      n_units = int(learning_config.output_head_type.split('_')[1])\n",
        "      n_units = n_units if n_units > 0 else num_ways\n",
        "      output_layers.append((n_units, False, 'relu'))\n",
        "    elif learning_config.output_head_type.startswith('trainable'):\n",
        "      n_units = int(learning_config.output_head_type.split('_')[1])\n",
        "      n_units = n_units if n_units > 0 else num_ways\n",
        "      output_layers.append((n_units, True, 'relu'))\n",
        "    # Final layer, this is the only layer when type=nohidden.\n",
        "    output_layers.append((num_ways, True, None))\n",
        "    output_head = tf.keras.Sequential()\n",
        "    for i, (n_features, is_trainable, f_activation) in enumerate(output_layers):\n",
        "      kwargs_dense = {'trainable': is_trainable}\n",
        "      if i == 0 and learning_config.output_head_zeroinit:\n",
        "        logging.info('First layer in output head is zero initialized.')\n",
        "        kwargs_dense['kernel_initializer'] = tf.zeros\n",
        "      new_layer = tf.keras.layers.Dense(\n",
        "          n_features, activation=f_activation, kernel_regularizer=regularizer,\n",
        "          **kwargs_dense)\n",
        "      output_head.add(new_layer)\n",
        "    return output_head\n",
        "\n",
        "  def evaluate(self, learning_config, support_dataset, query_dataset,\n",
        "               **unused_kwargs):\n",
        "    \"\"\"Performs evaluation on an episode.\n",
        "    Args:\n",
        "      learning_config: a `ConfigDict` specifying the learning configuration.\n",
        "      support_dataset: a `tf.data.Dataset` for the support set.\n",
        "      query_dataset: a `tf.data.Dataset` for the query set.\n",
        "    Returns:\n",
        "      metrics: dict mapping metric names to metrics.\n",
        "    \"\"\"\n",
        "    metrics = self._optimize_finetune(\n",
        "        learning_config, support_dataset, query_dataset)\n",
        "    return_dict = self._process_metrics(metrics)\n",
        "    return return_dict\n",
        "\n",
        "  def _optimize_finetune(self, learning_config, support_dataset, query_dataset,\n",
        "                         selected_feature_indices=None,\n",
        "                         return_output_head=False):\n",
        "    \"\"\"Optimize the output layers and possibly the backbones, too.\n",
        "    Args:\n",
        "      learning_config: A ConfigDict.\n",
        "      support_dataset: a `tf.data.Dataset` for the support set.\n",
        "      query_dataset: a `tf.data.Dataset` or None for the query set.\n",
        "      selected_feature_indices: defines which features are selected.\n",
        "      return_output_head: bool that decides what is returned. If true, this\n",
        "        means we return the trained output head and also don't calculate query\n",
        "        performance.\n",
        "    Returns:\n",
        "      lambda_logits: The optimized lambdas or None.\n",
        "      support_loss_iter: A list of iterate values.\n",
        "      support_accuracy_iter: A list of iterate values.\n",
        "      query_loss_iter: A list of iterate values.\n",
        "      query_accuracy_iter: A list of iterate values.\n",
        "    \"\"\"\n",
        "    if selected_feature_indices:\n",
        "      # Print statistics\n",
        "      for name, indices in zip(self.backbone_names, selected_feature_indices):\n",
        "        logging.info('Backbone: %s, selected %d', name, len(indices))\n",
        "    # Pre-generate the embeddings\n",
        "    with tf.device('/CPU:0'):\n",
        "      support_embeddings, support_labels = self._embed_dataset(support_dataset)\n",
        "      # Normalize the data\n",
        "      support_representation = self._process_embeddings(\n",
        "          support_embeddings, selected_feature_indices,\n",
        "          normalization=learning_config.feature_normalization)\n",
        "      logging.info('Support representation shape: %s',\n",
        "                   support_representation.shape)\n",
        "    if query_dataset is None:\n",
        "      query_labels = tf.constant([], dtype=support_labels.dtype)\n",
        "    elif learning_config.cached_eval:\n",
        "      with tf.device('/CPU:0'):\n",
        "        query_embeddings, query_labels = self._embed_dataset(query_dataset)\n",
        "        query_representation = self._process_embeddings(\n",
        "            query_embeddings, selected_feature_indices,\n",
        "            normalization=learning_config.feature_normalization)\n",
        "    else:\n",
        "      # We still need query labels to get number of classes. In some situations\n",
        "      # Support set might not have all classes, and then our output head\n",
        "      # would be smaller, which creates NaNs in loss calculation when\n",
        "      # tf.nn.sparse_softmax_cross_entropy_with_logits is used.\n",
        "      all_labels = []\n",
        "      for _, batch_labels in query_dataset:\n",
        "        all_labels.append(batch_labels)\n",
        "      query_labels = tf.concat(all_labels, axis=0)\n",
        "    support_loss_iter = []\n",
        "    support_accuracy_iter = []\n",
        "    query_loss_iter = []\n",
        "    query_accuracy_iter = []\n",
        "    all_labels = tf.concat([support_labels, query_labels], 0)\n",
        "    num_ways = tf.cast(tf.math.reduce_max(tf.unique(all_labels)[0]) + 1,\n",
        "                       tf.int32)\n",
        "    with self.strategy.scope():\n",
        "      if (learning_config.finetune_backbones and\n",
        "          learning_config.finetune_lr_multiplier != 1.):\n",
        "        learning_config = copy.deepcopy(learning_config)\n",
        "        new_lr = (learning_config['learning_rate'] *\n",
        "                  learning_config.finetune_lr_multiplier)\n",
        "        learning_config['learning_rate'] = new_lr\n",
        "        logging.info('Finetuning learning rate is updated to %s',\n",
        "                     new_lr)\n",
        "      if (learning_config.finetune_backbones and\n",
        "          learning_config.finetune_steps_multiplier != 1.):\n",
        "        learning_config = copy.deepcopy(learning_config)\n",
        "        new_steps = int(learning_config['training_steps'] *\n",
        "                        learning_config.finetune_steps_multiplier)\n",
        "        learning_config['training_steps'] = new_steps\n",
        "        logging.info('Finetuning training steps are updated to %s', new_steps)\n",
        "      optimizer = self._get_optimizer(learning_config, num_ways)\n",
        "      output_head = self._init_training_vars(num_ways, learning_config)\n",
        "      # Initialize the layer\n",
        "      output_head(support_representation[:1])\n",
        "\n",
        "    training_vars = output_head.trainable_variables\n",
        "    if learning_config.finetune_backbones:\n",
        "      for b in self.backbones:\n",
        "        training_vars.extend(b.trainable_variables)\n",
        "    else:\n",
        "      batch_size = learning_config.train_batch_size\n",
        "      # Regenerate the dataset with precomputed embeddings.\n",
        "      support_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "          (support_representation, support_labels)).batch(batch_size)\n",
        "      if query_dataset and learning_config.cached_eval:\n",
        "        query_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "            (query_representation, query_labels)).batch(\n",
        "                learning_config.eval_batch_size)\n",
        "    logging.info('Trainable variables: %s', [v.name for v in training_vars])\n",
        "    support_dataset = support_dataset.repeat()\n",
        "    dist_support_dataset = self.strategy.experimental_distribute_dataset(\n",
        "        support_dataset)\n",
        "    if query_dataset:\n",
        "      dist_query_dataset = self.strategy.experimental_distribute_dataset(\n",
        "          query_dataset)\n",
        "\n",
        "    @tf.function()\n",
        "    def _train_step(x, y):\n",
        "      with tf.GradientTape() as tape:\n",
        "        if learning_config.finetune_backbones:\n",
        "          # Pass the images through multiple backbones.\n",
        "          embeddings = self._embed_batch(x, is_training=True)\n",
        "          # Normalize the data\n",
        "          x = self._process_embeddings(\n",
        "              embeddings, selected_feature_indices,\n",
        "              normalization=learning_config.feature_normalization)\n",
        "        logits = output_head(x)\n",
        "        loss, accuracy = self._compute_loss_and_accuracy(\n",
        "            output_head, logits, y,\n",
        "            global_batch_size=learning_config.train_batch_size)\n",
        "      grads = tape.gradient(loss, training_vars)\n",
        "      optimizer.apply_gradients(zip(grads, training_vars))\n",
        "      return loss, accuracy\n",
        "\n",
        "    @tf.function()\n",
        "    def _eval_step(x, y):\n",
        "      if (learning_config.finetune_backbones or\n",
        "          not learning_config.cached_eval):\n",
        "        # Pass the images through multiple backbones.\n",
        "        embeddings = self._embed_batch(x, is_training=False)\n",
        "        # Normalize the data\n",
        "        x = self._process_embeddings(\n",
        "            embeddings, selected_feature_indices,\n",
        "            normalization=learning_config.feature_normalization)\n",
        "      logits = output_head(x)\n",
        "      loss, accuracy = self._compute_loss_and_accuracy(\n",
        "          output_head, logits, y,\n",
        "          global_batch_size=learning_config.eval_batch_size)\n",
        "      return loss, accuracy\n",
        "\n",
        "    for i, (x, y) in enumerate(dist_support_dataset):\n",
        "      if i == learning_config.training_steps:\n",
        "        break\n",
        "      per_replica_results = self.strategy.run(_train_step, args=(x, y))\n",
        "      pr_loss, pr_acc = per_replica_results\n",
        "      support_loss = self.strategy.reduce(\n",
        "          tf.distribute.ReduceOp.SUM, pr_loss, axis=None)\n",
        "      support_accuracy = self.strategy.reduce(\n",
        "          tf.distribute.ReduceOp.SUM, pr_acc, axis=None)\n",
        "      if query_dataset and (i % learning_config.log_freq == 0 or\n",
        "                            i == (learning_config.training_steps - 1)):\n",
        "        logging.info('Evaluating at iteration: %d', i)\n",
        "        all_losses = []\n",
        "        all_accs = []\n",
        "        for query_x, query_y in dist_query_dataset:\n",
        "          per_replica_results = self.strategy.run(_eval_step, args=(\n",
        "              query_x, query_y))\n",
        "          pr_loss, pr_acc = per_replica_results\n",
        "          c_query_loss = self.strategy.reduce(\n",
        "              tf.distribute.ReduceOp.SUM, pr_loss, axis=None)\n",
        "          c_query_accuracy = self.strategy.reduce(\n",
        "              tf.distribute.ReduceOp.SUM, pr_acc, axis=None)\n",
        "          all_losses.append(c_query_loss)\n",
        "          all_accs.append(c_query_accuracy)\n",
        "        # This assumes all batches are same size, so ensure that.\n",
        "        query_loss_iter.append(np.mean(all_losses))\n",
        "        query_accuracy_iter.append(np.mean(all_accs))\n",
        "      support_loss_iter.append(support_loss.numpy())\n",
        "      support_accuracy_iter.append(support_accuracy.numpy())\n",
        "    if learning_config.finetune_backbones:\n",
        "      # Reload the backbones to reset any changes made during finetuning.\n",
        "      with self.strategy.scope():\n",
        "        self.backbones, _, _ = self.load_backbones()\n",
        "    if return_output_head:\n",
        "      return output_head\n",
        "    else:\n",
        "      del output_head.layers[0].kernel\n",
        "      return (support_loss_iter, support_accuracy_iter, query_loss_iter,\n",
        "              query_accuracy_iter)\n",
        "\n",
        "\n",
        "def flatten_and_concat(output_dict, output_keys, pool_size=0, target_size=0,\n",
        "                       cls_token_pool='normal'):\n",
        "  \"\"\"Summarizes a dict of outputs into single feature vector.\"\"\"\n",
        "  # If target_size is given pool_size is ignored.\n",
        "  if cls_token_pool not in ('normal', 'only_cls', 'nopool_cls'):\n",
        "    raise ValueError(\"%s must be one of 'normal', 'only_cls', 'nopool_cls'\"\n",
        "                     % cls_token_pool)\n",
        "  all_features = []\n",
        "  for k in output_keys:\n",
        "    output = output_dict[k]\n",
        "    # TODO Make this more readable by making each branch a function.\n",
        "    if len(output.shape) == 4:\n",
        "      if target_size > 0:\n",
        "        # Overwrite pool size so that final output matches target_size as close\n",
        "        # as possible.\n",
        "        _, width, _, channels = output.shape\n",
        "        if channels >= target_size:\n",
        "          # Global pool.\n",
        "          pool_size = 0\n",
        "        else:\n",
        "          # Assuming square image.\n",
        "          n_patches_per_row = int(math.sqrt(target_size // channels))\n",
        "          pool_size = width // n_patches_per_row\n",
        "      if pool_size > 0:\n",
        "        output = tf.keras.layers.AveragePooling2D(\n",
        "            pool_size=pool_size, strides=pool_size)(output)\n",
        "        all_features.append(tf.keras.layers.Flatten()(output))\n",
        "      else:\n",
        "        # Global pool\n",
        "        all_features.append(tf.reduce_mean(output, axis=[1, 2]))\n",
        "    elif len(output.shape) == 3:\n",
        "      if cls_token_pool == 'only_cls':\n",
        "        output = output[:, 0, :]\n",
        "      else:\n",
        "        if cls_token_pool == 'nopool_cls':\n",
        "          # We will get the cls as it is and pool the rest.\n",
        "          cls_output, output = output[:, 0, :], output[:, 1:, :]\n",
        "        if target_size > 0:\n",
        "          # Overwrite pool size so that final output matches target_size as\n",
        "          # close as possible.\n",
        "          _, n_token, channels = output.shape\n",
        "          if channels >= target_size:\n",
        "            # Global pool.\n",
        "            pool_size = 0\n",
        "          else:\n",
        "            # Assuming square image.\n",
        "            n_groups = target_size / channels\n",
        "            pool_size = int(n_token / n_groups)\n",
        "        if pool_size > 0:\n",
        "          output = tf.keras.layers.AveragePooling1D(\n",
        "              pool_size=pool_size, strides=pool_size)(output)\n",
        "          output = tf.keras.layers.Flatten()(output)\n",
        "        else:\n",
        "          # Global pool\n",
        "          output = tf.reduce_mean(output, axis=[1])\n",
        "        if cls_token_pool == 'nopool_cls':\n",
        "          output = tf.concat([cls_output, output], axis=1)\n",
        "      all_features.append(output)\n",
        "    elif len(output.shape) == 2:\n",
        "      all_features.append(output)\n",
        "    else:\n",
        "      raise ValueError(\n",
        "          f'Output tensor: {k} with shape {output.shape} not 2D or 4D.')\n",
        "  return all_features\n"
      ],
      "metadata": {
        "id": "lE2tq8l5tajD"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}